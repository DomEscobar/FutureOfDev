# AI Coding Assistant Comparison Matrix (2026)

This matrix aggregates data from individual tool research files. Scores are on a 1-5 scale.

## Aggregated Scores

| Tool | Reasoning | Autonomy | Speed | Longevity | Flexibility | Openness | Total | Last Verified |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Cursor | 5 | 4 | 4 | 4 | 5 | 4 | 26 | 2026-02-15 |
| Windsurf | 5 | 5 | 5 | 3 | 5 | 5 | 28 | 2026-02-15 |
| Claude Code | 5 | 5 | 4 | 5 | 3 | 4 | 26 | 2026-02-15 |
| GitHub Copilot | 4 | 3 | 5 | 5 | 4 | 2 | 23 | 2026-02-15 |
| Tabnine | 3 | 2 | 4 | 4 | 4 | 5 | 22 | 2026-02-15 |

## Strategic Pillars

| Tool | License | Forkable | Model Arbitrage | Data Sovereignty |
| :--- | :---: | :---: | :---: | :---: |
| **Cursor** | Proprietary | No | High (BYO Key) | High (Zero-Retention) |
| **Windsurf** | Proprietary | No | Medium | Medium |
| **Claude Code** | Proprietary | No | Low (Anthropic) | Very High (Enterprise) |
| **Copilot** | Proprietary | No | None (OpenAI) | High (Enterprise) |
| **Tabnine** | MIT/Closed | Partially | High | Extreme (Air-gap) |

## Speed & Performance Benchmarks
*   **Leader in Autonomy:** **Windsurf** (Cascade) and **Claude Code** (Sub-agents).
*   **Leader in Latency:** **GitHub Copilot** (Autocomplete) dominates for sub-50ms "ghost text" completions.
*   **Leader in Ecosystem:** **Copilot** wins on ubiquity and enterprise-ready billing.

## Notable Facts (2025/2026):
*   **Consumptive Billing:** GitHub Copilot now enforces monthly "Premium Request" allowances (300/mo for Pro), ending the Era of Unlimited.
*   **The SWE-bench Gap:** Claude Code leads with 80.9%, while Copilot is seen as the "Standard Boilerplate Engine."
*   **Ecosystem Barrier:** Copilot represents the highest "Vendor Lock-in" (Locked models, no MCP, proprietary extensions).
