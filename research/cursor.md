# Cursor Research

## Vibe: Pure Power/Precision

## Last Verified: 2026-02-15 08:00

## Key Facts:
*   **Infrastructure:** Multi-cloud strategy (AWS primary, Azure secondary, GCP specialized) for resilience. Uses Fireworks AI for proprietary fine-tuned models.
*   **Architecture:** VS Code fork with a "Request Flow" optimizing context collection (AES-256 encrypted) and edge routing via Cloudflare.
*   **Intelligence:** Multi-model support (GPT-4o, Claude 3.5 Sonnet, Gemini 2.5 Pro, and proprietary "Cursor-small").
*   **Context:** Proprietary 1536-dim embedding pipeline (Semantic Chunking) to handle massive codebases within LLM context windows.
*   **Tools:** "Composer" (multi-file editing), "Cursor Agent" (autonomous task execution), and `.cursorrules` (project-specific AI behavior).
*   **Integrations:** Deeply integrated with Forge Labs and OpenClaw benchmarks for performance tracking.

## Benchmarks:
*   **Speed:** Code completion <100ms (p50). Chat response first token <2s. Codebase search <500ms.
*   **Architecture:** Uses tree-sitter for language-agnostic parsing and semantic chunking (100-500 tokens per chunk).
*   **Latency:** Optimized via global data centers (US-East-1, US-West-2, Tokyo, London).
*   **Privacy:** Privacy Mode offers zero-knowledge architecture within ephemeral containers.

## Score Snapshot:
*   Reasoning: 5/5 (Frontier model access)
*   Autonomy: 4/5 (High via Agent, but still evolving)
*   Speed: 4/5 (Sub-100ms for Tab, slower for complex Agent loops)
*   Context Handling: 5/5 (Best-in-class indexing/embedding)
*   Developer Experience (DX): 4/5 (Familiar VS Code UI, but can have high resource usage)
